# AirWriting

This project aims to address the communication challenges faced by the hearing-impaired community by developing a comprehensive solution that combines computer vision, deep learning, and user-friendly interfaces. The project seeks to create a robust Convolutional Neural Network (CNN) model capable of recognizing air-written Tamil characters in real-time. This model will be integrated into a Flask application that provides a user-friendly interface for practicing Air Writing and includes interactive quizzes to assess and improve user proficiency. The objective is to empower the hearing impaired with an accessible tool that enables effective communication, fosters inclusivity, and enhances their overall quality of life.

Functionalities:
+ Developed a robust and accurate Tamil character recognition CNN model capable of interpreting 
air-written gestures in real time.
+ Created a user-friendly interface that captured air-written gestures using OpenCV and MediaPipe and processed them for character recognition.
+ Developed a user-friendly Flask application that allowed users to practice air writing in Tamil conveniently.
+ Designed a quiz feature within the application that presented users with images of Tamil characters, words, or phrases, and prompted them to air-write the corresponding answers.
